{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the required libraries to use Azure ML\n",
        "import os\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Datastore, Dataset, Environment\n",
        "from azureml.data.datapath import DataPath\n",
        "from azureml.exceptions import UserErrorException\n",
        "\n",
        "print(\"Currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries specific to the ML model and code implementation\n",
        "import mlflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AzureML Workspace Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure to replace these with values match your Azure resources \n",
        "subscription_id = \"YOUR_SUBSCRIPTION_ID\"\n",
        "resource_group = \"YOUR_RESOURCE_GROUP_NAME\"\n",
        "workspace_name = \"YOUR_WORKSPACE_NAME\"\n",
        "workspace_region = \"YOUR_WORKSPACE_REGION\"\n",
        "container_registry_name = \"YOUR_CONTAINTER_REGISTRY_NAME\"\n",
        "storage_name = \"YOUR_STORAGE_ACCOUNT_NAME\"\n",
        "blob_datastore_name = \"YOUR_DATASTORE_NAME\"\n",
        "key_vault_name = \"YOUR_KEY_VAULT_NAME\"\n",
        "container_name = \"YOUR_STORAGE_CONTAINER_NAME\"\n",
        "storage_key = \"YOUR_STORAGE_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
        "    # Write the details of the workspace to a configuration file to the notebook library\n",
        "    print(\"Workspace configuration succeeded.\")\n",
        "except:\n",
        "    # Create a new workspace using the specified parameters\n",
        "    ws = Workspace.create(name = workspace_name,\n",
        "                        subscription_id = subscription_id,\n",
        "                        resource_group = resource_group, \n",
        "                        location = workspace_region,\n",
        "                        create_resource_group = True,\n",
        "                        sku = 'basic',\n",
        "                        exist_ok = True)\n",
        "    ws.get_details()\n",
        "    print(\"Workspace not accessible. Created a new workspace\")\n",
        "    \n",
        "# TODO: Work with environments\n",
        "myenv = Environment.from_pip_requirements(name = \"myenv\",\n",
        "                                        file_path = \"../../pipeline/environment/docker-contexts/python-and-pip/requirements.txt\")\n",
        "myenv.register(workspace=ws)\n",
        "ws.write_config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to the workspace\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import data from Azure Blobstorage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    blob_datastore = Datastore.get(ws, blob_datastore_name)\n",
        "    print(\"Found Blob Datastore with name: %s\" % blob_datastore_name)\n",
        "except UserErrorException:\n",
        "    blob_datastore = Datastore.register_azure_blob_container(\n",
        "        workspace=ws,\n",
        "        datastore_name=blob_datastore_name,\n",
        "        account_name=storage_name, \n",
        "        container_name=container_name,\n",
        "        account_key=storage_key)\n",
        "    print(\"Registered Blob Datastore with name: %s\" % blob_datastore_name)\n",
        "\n",
        "ws.set_default_datastore(blob_datastore_name)\n",
        "\n",
        "train = Dataset.Tabular.from_delimited_files(DataPath(blob_datastore, 'mnist_train.csv'))\n",
        "test = Dataset.Tabular.from_delimited_files(DataPath(blob_datastore, 'mnist_test.csv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Dataset versioning?\n",
        "train.register(workspace=ws, name='demo_train_set_mnist', description='training dataset', create_new_version=True)\n",
        "test.register(workspace=ws, name='demo_test_set_mnist', description='testing dataset', create_new_version=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/work-with-data/datasets-tutorial/train-with-datasets/train-with-datasets.ipynb\n",
        "train_df = train.to_pandas_dataframe()\n",
        "test_df = test.to_pandas_dataframe()\n",
        "\n",
        "# Separate labels from features, and normalize features on the fly\n",
        "x_train = train_df.iloc[:, 1:] / 255\n",
        "y_train = train_df.loc[:,\"label\"]\n",
        "x_test = test_df.iloc[:, 1:] / 255\n",
        "y_test = test_df.loc[:, \"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show some randomly chosen images from the traininng set.\n",
        "count = 0\n",
        "sample_size = 30\n",
        "plt.figure(figsize = (16, 6))\n",
        "for i in np.random.permutation(len(x_train))[:sample_size]:\n",
        "    count = count + 1\n",
        "    plt.subplot(1, sample_size, count)\n",
        "    plt.axhline('')\n",
        "    plt.axvline('')\n",
        "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
        "    plt.imshow(x_train.iloc[i].values.reshape((28,28)), cmap=plt.cm.Greys)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train model with MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# connect to your workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# create experiment and start logging to a new run in the experiment\n",
        "experiment_name = \"mnist-experiment-local\"\n",
        "\n",
        "# set up MLflow to track the metrics\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "mlflow.autolog()\n",
        "\n",
        "# set up the Logistic regression model\n",
        "reg = 0.5\n",
        "clf = LogisticRegression(\n",
        "    C=1.0 / reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42\n",
        ")\n",
        "\n",
        "# train the model\n",
        "with mlflow.start_run() as run:\n",
        "    clf.fit(x_train.values, y_train.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# register the model\n",
        "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
        "model = mlflow.register_model(model_uri, \"sklearn_mnist_model\")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "5dbe7d935004e9310a46bd29cb5bbb409a040f22b05fa1ad82418ef8c081a09c"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
